{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VideoToMask.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLlsPHh_4kpv"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "base_dir = root_dir + 'PredictionCode/'\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(base_dir)\n",
        "print(os.getcwd())\n",
        "print(os.listdir())\n",
        "os.chdir(base_dir)\n",
        "print(os.getcwd())\n",
        "print(os.listdir())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_z6cFLPpCi1"
      },
      "source": [
        "\n",
        "from torch import nn\n",
        "import torch\n",
        "import copy\n",
        "from torch.utils import data\n",
        "import numpy as np\n",
        "import random\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "from util.dataset import TrainDataset, TestDataset, ValDataset\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('\\ndevice = {0}\\n'.format(device))\n",
        "\n",
        "\n",
        "#instantiate model\n",
        "model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
        "        \n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "\n",
        "def instance_segmentation_api(im):\n",
        "    threshold = 0.75\n",
        "    img = np.array(im)\n",
        "    img = transforms.ToTensor()(img).to(device)\n",
        "    out = model([img])\n",
        "    # scores + masks\n",
        "    scores = out[0]['scores'].detach().cpu()\n",
        "    mask = out[0]['masks'].detach().cpu()\n",
        "    \n",
        "    if(len(mask) == 0):\n",
        "        return im\n",
        "    color_array = np.zeros([mask[0].shape[1], mask[0].shape[2],3], dtype=np.uint8)\n",
        "    best_idx = np.where(scores>threshold) \n",
        "    if len(best_idx)>0:\n",
        "       bgr_img = im\n",
        "       ax = plt.gca()\n",
        "       for id, b in enumerate(best_bboxes):\n",
        "           if classes[id].item() == 1:\n",
        "              found = mask[id][0].detach().clone().cpu().numpy()\n",
        "              color_array[found<0.5] = [255,255,255]\n",
        "\n",
        "       added_image = cv2.addWeighted(bgr_img, 0.5, color_array, 1, 0)       \n",
        "       return added_image\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo5iRJEBuaiX"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils import data\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import re\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "\n",
        "def transform_clip(video):\n",
        "    t_ = transforms.Compose([transforms.ToPILImage(),\n",
        "                                transforms.Resize((256, 256)),\n",
        "                                transforms.ToTensor(),\n",
        "                                ])\n",
        "    new_clip = []\n",
        "    for i in range(len(video)):\n",
        "        frame = t_(np.array(video[i]))\n",
        "        new_clip.append(frame)\n",
        "    return torch.stack(new_clip)\n",
        "\n",
        "def video_to_array():\n",
        "        directories = [x[0] for x in os.walk('./hmdb51_org')]\n",
        "        train_count = 0\n",
        "        test_count = 0\n",
        "        val_count = 0\n",
        "        count = 0\n",
        "        if os.path.exists('./PredData/train_mask/'):\n",
        "            shutil.rmtree('./PredData/train_mask/')\n",
        "        os.mkdir('./PredData/train_mask/')\n",
        "\n",
        "        if os.path.exists('./PredData/train_labels_mask/'):\n",
        "            shutil.rmtree('./PredData/train_labels_mask/')\n",
        "        os.mkdir('./PredData/train_labels_mask/')\n",
        "\n",
        "        if os.path.exists('./PredData/val_mask/'):\n",
        "            shutil.rmtree('./PredData/val_mask/')\n",
        "        os.mkdir('./PredData/val_mask/')\n",
        "\n",
        "        if os.path.exists('./PredData/val_labels_mask/'):\n",
        "            shutil.rmtree('./PredData/val_labels_mask/')\n",
        "        os.mkdir('./PredData/val_labels_mask/')\n",
        "\n",
        "        if os.path.exists('./PredData/test_mask/'):\n",
        "            shutil.rmtree('./PredData/test_mask/')\n",
        "        os.mkdir('./PredData/test_mask/')\n",
        "\n",
        "        if os.path.exists('./PredData/test_labels_mask/'):\n",
        "            shutil.rmtree('./PredData/test_labels_mask/')\n",
        "        os.mkdir('./PredData/test_labels_mask/')\n",
        "\n",
        "        \n",
        "        label = 0\n",
        "        labels = ['handstand', 'stand', 'smoke', 'somersault',\n",
        "                     'clap', 'smile', 'sit', 'wave', 'laugh', 'cartwheel']\n",
        "        for dir in directories:\n",
        "            skip = True\n",
        "            for l in labels:\n",
        "                if dir.__contains__(l):\n",
        "                    skip = False\n",
        "            if skip:\n",
        "                continue\n",
        "            print(dir)\n",
        "            videos = [f for f in listdir(dir) if isfile(join(dir, f))]\n",
        "            for video in videos:\n",
        "                arr = []\n",
        "                cap = cv2.VideoCapture(join(dir, video))\n",
        "                while cap.isOpened():\n",
        "                    ret, frame = cap.read()\n",
        "                    if frame is None:\n",
        "                        break\n",
        "                    print(np.shape(frame))\n",
        "                    frame = instance_segmentation_api(frame)\n",
        "                    arr.append(frame)\n",
        "                    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                        break\n",
        "                    if len(arr) == 70:\n",
        "                        if count % 10 == 0:\n",
        "                            torch.save(transform_clip(arr), './PredData/test_mask/' + str(test_count) + '.pt')\n",
        "                            torch.save(torch.tensor([label]), './PredData/test_labels_mask/' + str(test_count) + '.pt')\n",
        "                            test_count +=1\n",
        "                        elif count % 10 == 1:\n",
        "                            torch.save(transform_clip(arr), './PredData/val_mask/' + str(val_count) + '.pt')\n",
        "                            torch.save(torch.tensor([label]), './PredData/val_labels_mask/' + str(val_count) + '.pt')\n",
        "                            val_count +=1\n",
        "                        else:\n",
        "                            torch.save(transform_clip(arr), './PredData/train_mask/' + str(train_count) + '.pt')\n",
        "                            torch.save(torch.tensor([label]), './PredData/train_labels_mask/' + str(train_count) + '.pt')\n",
        "                            train_count +=1\n",
        "                        arr = []\n",
        "                        count +=1\n",
        "                cap.release()\n",
        "                cv2.destroyAllWindows()\n",
        "            label += 1\n",
        "\n",
        "\n",
        "video_to_array()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}